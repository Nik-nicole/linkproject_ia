{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: mediapipe in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (0.10.11)\n",
      "Requirement already satisfied: matplotlib in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: jax in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from mediapipe) (0.4.13)\n",
      "Requirement already satisfied: jaxlib in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from mediapipe) (0.4.13)\n",
      "Requirement already satisfied: torch in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from mediapipe) (0.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from jax->mediapipe) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from jax->mediapipe) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from jax->mediapipe) (8.0.0)\n",
      "Requirement already satisfied: filelock in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (3.15.4)\n",
      "Requirement already satisfied: sympy in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (1.13.0)\n",
      "Requirement already satisfied: networkx in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from torch->mediapipe) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe) (12.5.82)\n",
      "Requirement already satisfied: pycparser in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from sympy->torch->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/fabrica/anaconda3/envs/sigmov/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow  mediapipe matplotlib \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks (image, results):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR )\n",
    "    image.flags.wrietable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.wrietble = True\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 23:00:07.935139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:07.935167: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-29 23:00:21.553425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-29 23:00:21.553790: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.553920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-07-29 23:00:21.554336: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-29 23:00:21.564735: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobilenetv2 = hub.KerasLayer(url, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: 15000 muestras\n",
      "Forma de X: (15000, 1662)\n",
      "Forma de y: (15000,)\n",
      "Número de clases: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Iterar sobre todas las carpetas de frutas\n",
    "    for fruit_dir in os.listdir(data_dir):\n",
    "        fruit_dir_path = os.path.join(data_dir, fruit_dir)\n",
    "        if not os.path.isdir(fruit_dir_path):\n",
    "            continue\n",
    "\n",
    "        # Iterar sobre todas las subcarpetas dentro de la carpeta de fruta\n",
    "        for subdir in os.listdir(fruit_dir_path):\n",
    "            subdir_path = os.path.join(fruit_dir_path, subdir)\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                continue\n",
    "\n",
    "            # Iterar sobre todos los archivos .npy dentro de la subcarpeta\n",
    "            for archivo in os.listdir(subdir_path):\n",
    "                if not archivo.endswith('.npy'):\n",
    "                    continue\n",
    "\n",
    "                archivo_path = os.path.join(subdir_path, archivo)\n",
    "                frames = np.load(archivo_path)\n",
    "\n",
    "                # Agregar los datos y las etiquetas a las listas X y y\n",
    "                X.append(frames)\n",
    "                y.append(fruit_dir)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Ruta a la carpeta raíz que contiene las carpetas de frutas\n",
    "data_dir = '/home/fabrica/anaconda3/envs/linkproject_ia/fruit-model'\n",
    "\n",
    "# Cargar los datos\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Verificar la carga de datos\n",
    "if X.size == 0 or y.size == 0:\n",
    "    raise ValueError(\"No se han cargado datos. Verifica las rutas y los archivos.\")\n",
    "\n",
    "print(f\"Datos cargados: {len(X)} muestras\")\n",
    "print(f\"Forma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "print(f\"Número de clases: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "# Supongamos que X y y son tus datos de entrada y etiquetas respectivamente\n",
    "\n",
    "# Asegúrate de que las etiquetas sean enteros\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 07:10:04.542114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 07:10:04.542620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.542784: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.542928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.543065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.543198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.543319: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.543396: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.543497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-07-31 07:10:04.543509: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-31 07:10:04.553410: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Asegúrate de que el número de neuronas en la capa de salida sea igual al número de clases\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.7546 - accuracy: 0.3853 - val_loss: 1.3993 - val_accuracy: 0.5475\n",
      "Epoch 2/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 1.2729 - accuracy: 0.5729 - val_loss: 1.1429 - val_accuracy: 0.6314\n",
      "Epoch 3/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 1.0352 - accuracy: 0.6624 - val_loss: 0.9037 - val_accuracy: 0.7213\n",
      "Epoch 4/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.8781 - accuracy: 0.7179 - val_loss: 0.8323 - val_accuracy: 0.7391\n",
      "Epoch 5/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.8026 - accuracy: 0.7379 - val_loss: 0.7313 - val_accuracy: 0.7700\n",
      "Epoch 6/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.7650 - val_loss: 0.6653 - val_accuracy: 0.7793\n",
      "Epoch 7/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.7776 - val_loss: 0.6919 - val_accuracy: 0.7626\n",
      "Epoch 8/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.6248 - accuracy: 0.8008 - val_loss: 0.5697 - val_accuracy: 0.8185\n",
      "Epoch 9/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.8114 - val_loss: 0.5632 - val_accuracy: 0.8151\n",
      "Epoch 10/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.8286 - val_loss: 0.5648 - val_accuracy: 0.8148\n",
      "Epoch 11/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.5135 - accuracy: 0.8336 - val_loss: 0.4554 - val_accuracy: 0.8543\n",
      "Epoch 12/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.4859 - accuracy: 0.8436 - val_loss: 0.4281 - val_accuracy: 0.8608\n",
      "Epoch 13/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.8519 - val_loss: 0.4050 - val_accuracy: 0.8724\n",
      "Epoch 14/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.4274 - accuracy: 0.8629 - val_loss: 0.4743 - val_accuracy: 0.8432\n",
      "Epoch 15/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.4349 - accuracy: 0.8579 - val_loss: 0.3889 - val_accuracy: 0.8707\n",
      "Epoch 16/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.4163 - accuracy: 0.8667 - val_loss: 0.3764 - val_accuracy: 0.8771\n",
      "Epoch 17/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8734 - val_loss: 0.3913 - val_accuracy: 0.8736\n",
      "Epoch 18/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8720 - val_loss: 0.3293 - val_accuracy: 0.8983\n",
      "Epoch 19/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8805 - val_loss: 0.3005 - val_accuracy: 0.9063\n",
      "Epoch 20/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3587 - accuracy: 0.8830 - val_loss: 0.3052 - val_accuracy: 0.9007\n",
      "Epoch 21/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8905 - val_loss: 0.3423 - val_accuracy: 0.8922\n",
      "Epoch 22/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8908 - val_loss: 0.3012 - val_accuracy: 0.9049\n",
      "Epoch 23/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3221 - accuracy: 0.8956 - val_loss: 0.3392 - val_accuracy: 0.8901\n",
      "Epoch 24/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.3118 - accuracy: 0.8995 - val_loss: 0.2905 - val_accuracy: 0.9138\n",
      "Epoch 25/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2993 - accuracy: 0.9061 - val_loss: 0.3438 - val_accuracy: 0.8903\n",
      "Epoch 26/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.9070 - val_loss: 0.2695 - val_accuracy: 0.9172\n",
      "Epoch 27/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2927 - accuracy: 0.9061 - val_loss: 0.2731 - val_accuracy: 0.9159\n",
      "Epoch 28/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.9151 - val_loss: 0.3410 - val_accuracy: 0.8827\n",
      "Epoch 29/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2771 - accuracy: 0.9126 - val_loss: 0.2534 - val_accuracy: 0.9208\n",
      "Epoch 30/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.9097 - val_loss: 0.2363 - val_accuracy: 0.9295\n",
      "Epoch 31/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.9108 - val_loss: 0.2769 - val_accuracy: 0.9129\n",
      "Epoch 32/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2589 - accuracy: 0.9182 - val_loss: 0.2703 - val_accuracy: 0.9118\n",
      "Epoch 33/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2641 - accuracy: 0.9138 - val_loss: 0.2223 - val_accuracy: 0.9311\n",
      "Epoch 34/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2687 - accuracy: 0.9137 - val_loss: 0.2519 - val_accuracy: 0.9218\n",
      "Epoch 35/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.9183 - val_loss: 0.2455 - val_accuracy: 0.9253\n",
      "Epoch 36/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9235 - val_loss: 0.2087 - val_accuracy: 0.9357\n",
      "Epoch 37/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.9115 - val_loss: 0.2206 - val_accuracy: 0.9306\n",
      "Epoch 38/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2555 - accuracy: 0.9181 - val_loss: 0.2012 - val_accuracy: 0.9369\n",
      "Epoch 39/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9264 - val_loss: 0.1935 - val_accuracy: 0.9397\n",
      "Epoch 40/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2339 - accuracy: 0.9240 - val_loss: 0.2997 - val_accuracy: 0.8993\n",
      "Epoch 41/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.9251 - val_loss: 0.2015 - val_accuracy: 0.9383\n",
      "Epoch 42/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9247 - val_loss: 0.2538 - val_accuracy: 0.9151\n",
      "Epoch 43/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2276 - accuracy: 0.9260 - val_loss: 0.1968 - val_accuracy: 0.9331\n",
      "Epoch 44/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9239 - val_loss: 0.2084 - val_accuracy: 0.9347\n",
      "Epoch 45/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2429 - accuracy: 0.9206 - val_loss: 0.1794 - val_accuracy: 0.9465\n",
      "Epoch 46/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2213 - accuracy: 0.9287 - val_loss: 0.2490 - val_accuracy: 0.9187\n",
      "Epoch 47/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9313 - val_loss: 0.3008 - val_accuracy: 0.8949\n",
      "Epoch 48/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9227 - val_loss: 0.1863 - val_accuracy: 0.9431\n",
      "Epoch 49/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9309 - val_loss: 0.1882 - val_accuracy: 0.9399\n",
      "Epoch 50/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2247 - accuracy: 0.9241 - val_loss: 0.1966 - val_accuracy: 0.9370\n",
      "Epoch 51/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2170 - accuracy: 0.9291 - val_loss: 0.2489 - val_accuracy: 0.9098\n",
      "Epoch 52/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2136 - accuracy: 0.9291 - val_loss: 0.1799 - val_accuracy: 0.9440\n",
      "Epoch 53/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2062 - accuracy: 0.9339 - val_loss: 0.1747 - val_accuracy: 0.9432\n",
      "Epoch 54/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2072 - accuracy: 0.9335 - val_loss: 0.2806 - val_accuracy: 0.9077\n",
      "Epoch 55/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.9301 - val_loss: 0.2102 - val_accuracy: 0.9335\n",
      "Epoch 56/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9325 - val_loss: 0.2305 - val_accuracy: 0.9212\n",
      "Epoch 57/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1994 - accuracy: 0.9357 - val_loss: 0.1526 - val_accuracy: 0.9537\n",
      "Epoch 58/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2157 - accuracy: 0.9272 - val_loss: 0.2367 - val_accuracy: 0.9227\n",
      "Epoch 59/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2094 - accuracy: 0.9315 - val_loss: 0.1774 - val_accuracy: 0.9440\n",
      "Epoch 60/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2082 - accuracy: 0.9305 - val_loss: 0.1520 - val_accuracy: 0.9529\n",
      "Epoch 61/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.9349 - val_loss: 0.1524 - val_accuracy: 0.9549\n",
      "Epoch 62/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.9316 - val_loss: 0.1525 - val_accuracy: 0.9474\n",
      "Epoch 63/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1856 - accuracy: 0.9403 - val_loss: 0.1700 - val_accuracy: 0.9443\n",
      "Epoch 64/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1857 - accuracy: 0.9377 - val_loss: 0.1539 - val_accuracy: 0.9492\n",
      "Epoch 65/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1958 - accuracy: 0.9359 - val_loss: 0.1557 - val_accuracy: 0.9487\n",
      "Epoch 66/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1879 - accuracy: 0.9374 - val_loss: 0.1545 - val_accuracy: 0.9487\n",
      "Epoch 67/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1895 - accuracy: 0.9377 - val_loss: 0.1943 - val_accuracy: 0.9365\n",
      "Epoch 68/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.2031 - accuracy: 0.9345 - val_loss: 0.1504 - val_accuracy: 0.9525\n",
      "Epoch 69/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1779 - accuracy: 0.9415 - val_loss: 0.1746 - val_accuracy: 0.9435\n",
      "Epoch 70/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9365 - val_loss: 0.1948 - val_accuracy: 0.9363\n",
      "Epoch 71/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1849 - accuracy: 0.9377 - val_loss: 0.1766 - val_accuracy: 0.9445\n",
      "Epoch 72/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1717 - accuracy: 0.9439 - val_loss: 0.1492 - val_accuracy: 0.9503\n",
      "Epoch 73/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1796 - accuracy: 0.9413 - val_loss: 0.1627 - val_accuracy: 0.9441\n",
      "Epoch 74/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1735 - accuracy: 0.9425 - val_loss: 0.1515 - val_accuracy: 0.9508\n",
      "Epoch 75/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1612 - accuracy: 0.9479 - val_loss: 0.1381 - val_accuracy: 0.9574\n",
      "Epoch 76/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.9410 - val_loss: 0.2357 - val_accuracy: 0.9188\n",
      "Epoch 77/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1726 - accuracy: 0.9434 - val_loss: 0.1675 - val_accuracy: 0.9421\n",
      "Epoch 78/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9420 - val_loss: 0.1927 - val_accuracy: 0.9393\n",
      "Epoch 79/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9407 - val_loss: 0.2669 - val_accuracy: 0.9052\n",
      "Epoch 80/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.9444 - val_loss: 0.1437 - val_accuracy: 0.9511\n",
      "Epoch 81/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1670 - accuracy: 0.9448 - val_loss: 0.1460 - val_accuracy: 0.9510\n",
      "Epoch 82/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1588 - accuracy: 0.9465 - val_loss: 0.1361 - val_accuracy: 0.9555\n",
      "Epoch 83/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1596 - accuracy: 0.9465 - val_loss: 0.1764 - val_accuracy: 0.9433\n",
      "Epoch 84/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1586 - accuracy: 0.9465 - val_loss: 0.1457 - val_accuracy: 0.9532\n",
      "Epoch 85/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1615 - accuracy: 0.9462 - val_loss: 0.1409 - val_accuracy: 0.9545\n",
      "Epoch 86/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1578 - accuracy: 0.9487 - val_loss: 0.1682 - val_accuracy: 0.9448\n",
      "Epoch 87/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9415 - val_loss: 0.1409 - val_accuracy: 0.9554\n",
      "Epoch 88/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1576 - accuracy: 0.9456 - val_loss: 0.1178 - val_accuracy: 0.9623\n",
      "Epoch 89/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1555 - accuracy: 0.9474 - val_loss: 0.1478 - val_accuracy: 0.9475\n",
      "Epoch 90/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9486 - val_loss: 0.1128 - val_accuracy: 0.9631\n",
      "Epoch 91/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1583 - accuracy: 0.9462 - val_loss: 0.1546 - val_accuracy: 0.9454\n",
      "Epoch 92/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1531 - accuracy: 0.9490 - val_loss: 0.2599 - val_accuracy: 0.9125\n",
      "Epoch 93/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1486 - accuracy: 0.9523 - val_loss: 0.1384 - val_accuracy: 0.9529\n",
      "Epoch 94/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1517 - accuracy: 0.9481 - val_loss: 0.1799 - val_accuracy: 0.9366\n",
      "Epoch 95/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1564 - accuracy: 0.9486 - val_loss: 0.1566 - val_accuracy: 0.9492\n",
      "Epoch 96/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1496 - accuracy: 0.9505 - val_loss: 0.1354 - val_accuracy: 0.9561\n",
      "Epoch 97/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1407 - accuracy: 0.9523 - val_loss: 0.1681 - val_accuracy: 0.9439\n",
      "Epoch 98/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9473 - val_loss: 0.1858 - val_accuracy: 0.9307\n",
      "Epoch 99/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1515 - accuracy: 0.9493 - val_loss: 0.1157 - val_accuracy: 0.9635\n",
      "Epoch 100/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1399 - accuracy: 0.9511 - val_loss: 0.1469 - val_accuracy: 0.9497\n",
      "Epoch 101/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1398 - accuracy: 0.9516 - val_loss: 0.2156 - val_accuracy: 0.9215\n",
      "Epoch 102/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9477 - val_loss: 0.1303 - val_accuracy: 0.9563\n",
      "Epoch 103/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1444 - accuracy: 0.9535 - val_loss: 0.1756 - val_accuracy: 0.9359\n",
      "Epoch 104/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1460 - accuracy: 0.9500 - val_loss: 0.1285 - val_accuracy: 0.9567\n",
      "Epoch 105/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9497 - val_loss: 0.1183 - val_accuracy: 0.9613\n",
      "Epoch 106/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1316 - accuracy: 0.9578 - val_loss: 0.1198 - val_accuracy: 0.9599\n",
      "Epoch 107/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1333 - accuracy: 0.9548 - val_loss: 0.1077 - val_accuracy: 0.9649\n",
      "Epoch 108/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1507 - accuracy: 0.9490 - val_loss: 0.1842 - val_accuracy: 0.9359\n",
      "Epoch 109/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1342 - accuracy: 0.9540 - val_loss: 0.1250 - val_accuracy: 0.9585\n",
      "Epoch 110/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1443 - accuracy: 0.9515 - val_loss: 0.1317 - val_accuracy: 0.9551\n",
      "Epoch 111/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1337 - accuracy: 0.9546 - val_loss: 0.1035 - val_accuracy: 0.9662\n",
      "Epoch 112/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1275 - accuracy: 0.9583 - val_loss: 0.1253 - val_accuracy: 0.9567\n",
      "Epoch 113/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9519 - val_loss: 0.1454 - val_accuracy: 0.9501\n",
      "Epoch 114/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9566 - val_loss: 0.1627 - val_accuracy: 0.9433\n",
      "Epoch 115/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9517 - val_loss: 0.1261 - val_accuracy: 0.9591\n",
      "Epoch 116/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1358 - accuracy: 0.9534 - val_loss: 0.1644 - val_accuracy: 0.9416\n",
      "Epoch 117/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1357 - accuracy: 0.9538 - val_loss: 0.1642 - val_accuracy: 0.9458\n",
      "Epoch 118/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1263 - accuracy: 0.9587 - val_loss: 0.1296 - val_accuracy: 0.9569\n",
      "Epoch 119/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1291 - accuracy: 0.9575 - val_loss: 0.0831 - val_accuracy: 0.9740\n",
      "Epoch 120/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1279 - accuracy: 0.9569 - val_loss: 0.1690 - val_accuracy: 0.9365\n",
      "Epoch 121/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1246 - accuracy: 0.9576 - val_loss: 0.1444 - val_accuracy: 0.9501\n",
      "Epoch 122/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9537 - val_loss: 0.0949 - val_accuracy: 0.9682\n",
      "Epoch 123/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9559 - val_loss: 0.1201 - val_accuracy: 0.9603\n",
      "Epoch 124/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1298 - accuracy: 0.9559 - val_loss: 0.1191 - val_accuracy: 0.9607\n",
      "Epoch 125/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1187 - accuracy: 0.9588 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 126/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1358 - accuracy: 0.9552 - val_loss: 0.1820 - val_accuracy: 0.9337\n",
      "Epoch 127/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1293 - accuracy: 0.9568 - val_loss: 0.1930 - val_accuracy: 0.9335\n",
      "Epoch 128/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9601 - val_loss: 0.1198 - val_accuracy: 0.9589\n",
      "Epoch 129/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9571 - val_loss: 0.2695 - val_accuracy: 0.9113\n",
      "Epoch 130/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9611 - val_loss: 0.0888 - val_accuracy: 0.9695\n",
      "Epoch 131/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1284 - accuracy: 0.9558 - val_loss: 0.1846 - val_accuracy: 0.9362\n",
      "Epoch 132/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1069 - accuracy: 0.9646 - val_loss: 0.1388 - val_accuracy: 0.9511\n",
      "Epoch 133/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1254 - accuracy: 0.9587 - val_loss: 0.0816 - val_accuracy: 0.9726\n",
      "Epoch 134/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9591 - val_loss: 0.1214 - val_accuracy: 0.9567\n",
      "Epoch 135/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1058 - accuracy: 0.9637 - val_loss: 0.1108 - val_accuracy: 0.9629\n",
      "Epoch 136/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1258 - accuracy: 0.9581 - val_loss: 0.1731 - val_accuracy: 0.9380\n",
      "Epoch 137/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9533 - val_loss: 0.1034 - val_accuracy: 0.9636\n",
      "Epoch 138/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9552 - val_loss: 0.0989 - val_accuracy: 0.9658\n",
      "Epoch 139/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9581 - val_loss: 0.0965 - val_accuracy: 0.9665\n",
      "Epoch 140/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1111 - accuracy: 0.9619 - val_loss: 0.0993 - val_accuracy: 0.9653\n",
      "Epoch 141/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.9608 - val_loss: 0.1143 - val_accuracy: 0.9596\n",
      "Epoch 142/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9621 - val_loss: 0.1024 - val_accuracy: 0.9645\n",
      "Epoch 143/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9592 - val_loss: 0.0806 - val_accuracy: 0.9727\n",
      "Epoch 144/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9585 - val_loss: 0.0780 - val_accuracy: 0.9742\n",
      "Epoch 145/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1122 - accuracy: 0.9621 - val_loss: 0.0892 - val_accuracy: 0.9712\n",
      "Epoch 146/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9620 - val_loss: 0.1347 - val_accuracy: 0.9537\n",
      "Epoch 147/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9589 - val_loss: 0.0828 - val_accuracy: 0.9729\n",
      "Epoch 148/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9625 - val_loss: 0.1063 - val_accuracy: 0.9640\n",
      "Epoch 149/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9624 - val_loss: 0.0806 - val_accuracy: 0.9739\n",
      "Epoch 150/150\n",
      "469/469 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9636 - val_loss: 0.0951 - val_accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x77a2ce086ee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, validation_data=(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 0s 391us/step - loss: 0.0951 - accuracy: 0.9673\n",
      "Loss: 0.0951373502612114, Accuracy: 0.9673333168029785\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mi_modelo2.5.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722422844.468701   11377 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1722422844.547514  126445 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA T1000 8GB/PCIe/SSE2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model('mi_modelo.h5')\n",
    "\n",
    "# Inicializar MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Función para extraer características y hacer predicción\n",
    "def predict_frame(frame):\n",
    "    # Convertir BGR a RGB para MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Procesar el frame con MediaPipe Holistic\n",
    "    results = holistic.process(rgb_frame)\n",
    "    \n",
    "    # Extraer características del cuerpo entero\n",
    "    landmarks = results.pose_landmarks\n",
    "    if landmarks:\n",
    "        landmark_array = np.array([[lm.x, lm.y, lm.z] for lm in landmarks.landmark]).flatten()\n",
    "        if len(landmark_array) == 554 * 3:  # Verificar que tengamos el tamaño correcto\n",
    "            # Normalizar y hacer predicción\n",
    "            input_frame = landmark_array / np.max(landmark_array)  # Normalización simple\n",
    "            input_frame = np.expand_dims(input_frame, axis=0)  # Agregar dimensión de lote\n",
    "            \n",
    "            # Realizar predicción\n",
    "            predictions = model.predict(input_frame)\n",
    "            return predictions\n",
    "    return np.zeros((1, len(clases)))  # Devolver un array de ceros si no hay landmarks\n",
    "\n",
    "# Captura de video\n",
    "cap = cv2.VideoCapture(0)  # 0 para la cámara por defecto\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "\n",
    "    # Realizar predicción\n",
    "    predictions = predict_frame(frame)\n",
    "    \n",
    "    # Mostrar la predicción en el frame\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    cv2.putText(frame, f'Predicción: {predicted_class}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Dibujar los resultados de MediaPipe en el frame\n",
    "    results = holistic.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "    # Mostrar el frame\n",
    "    cv2.imshow('Predicción en Vivo', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-20:]\n",
    "        \n",
    "        if len(sequence) == 20:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sigmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
