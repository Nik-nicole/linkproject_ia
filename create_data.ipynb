{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprobar que el pc tiene GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actualizar PIP (Si es necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar todas las dependecias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt  # type: ignore\n",
    "from tensorflow.keras.layers import Dense  # type: ignore\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy  # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los métodos necesarios  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labeling_images import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de las carpetas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta general\n",
    "DATA_PATH = os.path.join(\"D_CORTO\")\n",
    "# Clases\n",
    "actions = np.array([\"manzana\", \"coco\"])\n",
    "# Número de secuencias\n",
    "no_sequences = 2\n",
    "# Secuencia de frames o fotos\n",
    "sequence_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manzana' 'coco']\n"
     ]
    }
   ],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la carpeta donde seran guardados los frames de cadad video\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captura de los frames, en este caso fotos de la seña que sean importante (4 frames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import mediapipe as mp\n",
    "\n",
    "\n",
    "# # Inicializar la captura de video\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# photo_count = {action: {str(sequence): 0 for sequence in range(no_sequences)} for action in actions}\n",
    "\n",
    "\n",
    "# print(\"Presiona 'd' para tomar una foto. Presiona 'q' para salir.\")\n",
    "\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Hacer las detecciones y dibujar los puntos clave\n",
    "#         image, results = mediapipe_detection(frame, holistic)\n",
    "#         draw_styled_landmarks(image, results)\n",
    "\n",
    "#         # Mostrar el video en una ventana\n",
    "#         cv2.imshow('Video', image)\n",
    "\n",
    "#         # Esperar a que se presione una tecla\n",
    "#         key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "#         if key == ord('q'):\n",
    "#             break\n",
    "#         elif key == ord('d'):\n",
    "#              for action in actions:\n",
    "#                 # Loop through sequences aka videos\n",
    "#                 for sequence in range(no_sequences):#start_folder, start_folder+no_sequences):\n",
    "#                     # Loop through video length aka sequence length\n",
    "#                     for frame_num in range(sequence_length):\n",
    "\n",
    "#                         # Read feed\n",
    "#                         ret, frame = cap.read()\n",
    "                                                        \n",
    "#                         # Make detections\n",
    "#                         image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "#                         # Draw landmarks\n",
    "#                         draw_styled_landmarks(image, results)\n",
    "                        \n",
    "#                         # NEW Apply wait logic\n",
    "#                         if frame_num == 0: \n",
    "#                             cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "#                             cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                             # Show to screen\n",
    "#                             cv2.imshow('OpenCV Feed', image)\n",
    "#                             cv2.waitKey(500)\n",
    "#                         else: \n",
    "#                             cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                             # Show to screen\n",
    "#                             cv2.imshow('OpenCV Feed', image)\n",
    "                        \n",
    "#                         # NEW Export keypoints\n",
    "#                         keypoints = extract_keypoints(results)\n",
    "#                         npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "#                         np.save(npy_path, keypoints)\n",
    "#                     # Show to screen\n",
    "#                         cv2.imshow('OpenCV Feed', image)\n",
    "#                         cv2.waitKey(500)\n",
    "#                         photo_filename = f'{photo_count[action][str(sequence)]}.jpg'\n",
    "#                         photo_path = os.path.join(DATA_PATH, action, str(sequence), photo_filename)\n",
    "#                         cv2.imwrite(photo_path, image)\n",
    "#                         photo_count[action][str(sequence)] += 1\n",
    "#                         print(f'Foto guardada: {photo_path}')\n",
    "\n",
    "#                         # Extraer y guardar los puntos clave\n",
    "#                         keypoints = extract_keypoints(results)\n",
    "#                         npy_path = os.path.join(DATA_PATH, action, str(sequence), f'{photo_count[action][str(sequence)] - 1}.npy')\n",
    "#                         np.save(npy_path, keypoints)\n",
    "#                         print(f'Puntos clave guardados: {npy_path}')\n",
    "#                         break\n",
    "\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presiona 'd' para tomar una foto. Presiona 'q' para salir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1723223959.184038   29540 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1723223959.258827   45862 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 560.28.03), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "W0000 00:00:1723223959.300855   45850 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.311228   45851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.311880   45856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.312107   45861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.312776   45859 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.316542   45855 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.321957   45852 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723223959.324354   45851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/home/popetasmixs/anaconda3/envs/sena/lib/python3.9/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Inicializar la captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Variables de configuración\n",
    "actions = ['coco', 'manzana']  # Lista de frutas\n",
    "sub_folders = [str(i) for i in range(2)]  # Sub carpetas numeradas de 0 a 1\n",
    "sequence_length = 4  # Número de fotos por secuencia\n",
    "\n",
    "# Crear un diccionario para contar las fotos tomadas en cada secuencia\n",
    "photo_count = {action: {sub_folder: 0 for sub_folder in sub_folders} for action in actions}\n",
    "action_index = 0  # Índice para la fruta actual\n",
    "subfolder_index = 0  # Índice para la sub carpeta actual\n",
    "countdown = sequence_length  # Contador inicial para las fotos\n",
    "\n",
    "print(\"Presiona 'd' para tomar una foto. Presiona 'q' para salir.\")\n",
    "\n",
    "with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Hacer las detecciones y dibujar los puntos clave\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Mostrar el video en una ventana\n",
    "        cv2.putText(image, f'Fotos restantes: {countdown}', (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, f'Carpeta: {actions[action_index]} Sub carpeta: {subfolder_index}', (10, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('Video', image)\n",
    "\n",
    "        # Esperar a que se presione una tecla\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        elif key == ord('d'):\n",
    "            # Tomar la foto y guardarla en formato JPG\n",
    "            current_action = actions[action_index]\n",
    "            current_subfolder = sub_folders[subfolder_index]\n",
    "            photo_filename = f'{photo_count[current_action][current_subfolder]}.jpg'\n",
    "            photo_path = os.path.join(DATA_PATH, current_action, current_subfolder, photo_filename)\n",
    "            cv2.imwrite(photo_path, image)\n",
    "            photo_count[current_action][current_subfolder] += 1\n",
    "\n",
    "            # Extraer y guardar los puntos clave en formato NPY\n",
    "            keypoints = extract_keypoints(results)\n",
    "            npy_filename = f'{photo_count[current_action][current_subfolder] - 1}.npy'\n",
    "            npy_path = os.path.join(DATA_PATH, current_action, current_subfolder, npy_filename)\n",
    "            np.save(npy_path, keypoints)\n",
    "\n",
    "            # Actualizar el contador y mostrarlo en pantalla\n",
    "            countdown -= 1\n",
    "            cv2.putText(image, f'Foto guardada: {photo_filename}', (10, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.imshow('Video', image)\n",
    "\n",
    "            if countdown == 0:\n",
    "                # Cambiar a la siguiente sub carpeta\n",
    "                subfolder_index += 1\n",
    "                countdown = sequence_length  # Reiniciar el contador\n",
    "\n",
    "                if subfolder_index >= len(sub_folders):\n",
    "                    subfolder_index = 0\n",
    "                    action_index += 1\n",
    "\n",
    "                    if action_index >= len(actions):\n",
    "                        cv2.putText(image, 'Todas las fotos completadas', (10, 200),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "                        cv2.imshow('Video', image)\n",
    "                        cv2.waitKey(2000)\n",
    "                        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigmov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
